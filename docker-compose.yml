version: '3.8'
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    ports:
      - "9870:9870"
    volumes:
      - ./hadoop-config:/etc/hadoop
      - hadoop-namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    depends_on:
      - namenode
    volumes:
      - ./hadoop-config:/etc/hadoop
      - hadoop-datanode:/hadoop/dfs/data
    environment:
      - NAMENODE_HOST=namenode

  zookeeper:
    image: bitnami/zookeeper:3.7
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"

  kafka:
    image: bitnami/kafka:3
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CREATE_TOPICS=Captions:1:1,SearchQueries:1:1,SearchResults:1:1

  hadoop-init:
    build:
      context: ./hadoop-init
    container_name: hadoop-init
    depends_on:
      - namenode
      - datanode
    volumes:
      - ./data:/data
    entrypoint: ["/bin/bash","/init.sh"]

  producer:
    build:
      context: ./producer
    container_name: producer
    depends_on:
      - kafka
    volumes:
      - ./data:/data
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092

  search-producer:
    build:
      context: ./search_producer
    container_name: search-producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092

  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    depends_on:
      - namenode
    environment:
      - SPARK_MODE=master
      - HADOOP_CONF_DIR=/etc/hadoop
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - HDFS_URI=hdfs://namenode:9000
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./hadoop-config:/etc/hadoop
      - ./spark_jobs:/opt/app

  spark-worker:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - HADOOP_CONF_DIR=/etc/hadoop
    volumes:
      - ./hadoop-config:/etc/hadoop
      - ./spark_jobs:/opt/app

volumes:
  hadoop-namenode:
  hadoop-datanode:
